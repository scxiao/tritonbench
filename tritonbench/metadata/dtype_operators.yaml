# =================================================================
# This file is generated by benchmarks/gen_metadata/run.py
# List of operators and their default dtype
# =================================================================
addmm: fp16
bf16xint16_gemm: bypass
cross_entropy: bypass
embedding: bypass
flash_attention: bf16
flex_attention: bf16
fp8_attention: fp8
fp8_fused_quant_gemm_rowwise: fp8
fp8_gemm: fp8
fp8_gemm_blockwise: fp8
fp8_gemm_rowwise: fp8
fp8_gemm_rowwise_grouped: fp8
fused_linear_cross_entropy: bypass
fused_linear_jsd: bypass
gather_gemv: bypass
geglu: bypass
gemm: fp16
grouped_gemm: fp16
int4_gemm: bypass
jagged_layer_norm: fp32
jagged_mean: fp32
jagged_softmax: fp32
jagged_sum: fp32
jsd: bypass
kl_div: bypass
launch_latency: bypass
layer_norm: bypass
low_mem_dropout: bypass
mixed_gemm: bf16
ragged_attention: bf16
rms_norm: bypass
rope: bypass
softmax: bypass
sum: bypass
swiglu: bypass
template_attention: bypass
test_op: bypass
vector_add: bypass
welford: bypass
